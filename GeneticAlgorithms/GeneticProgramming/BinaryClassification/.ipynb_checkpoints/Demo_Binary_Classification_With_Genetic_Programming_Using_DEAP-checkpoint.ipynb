{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Binary classification with Genetic Programming using DEAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADELE\\Anaconda2\\envs\\DeeplearningEnv\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import gplearn\n",
    "import os\n",
    "import enum\n",
    "\n",
    "import DeapWrapperComponent as de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constant and variable settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_LINE = '\\n'\n",
    "DATA_PATH = r'.\\Data'\n",
    "def getDataPaths():\n",
    "    paths = [x for x in os.listdir(DATA_PATH)]\n",
    "    paths.sort()\n",
    "    paths = [os.path.join(DATA_PATH, x) for x in paths]\n",
    "    paths = tuple(paths)\n",
    "    return paths\n",
    "\n",
    "BREAST_PATH, HORSE_PATH, IONOSPHERE_PATH, PIMA_PATH, SONAR_PATH, SPAMBASE_TEST, SPAMBASE_TRAIN = getDataPaths()\n",
    "\n",
    "class ProblemType(enum.Enum):\n",
    "    breast_cancer_problem = 0\n",
    "    horse_problem = 1\n",
    "    ionospere_problem = 2\n",
    "    sonar_problem = 3\n",
    "    pima_problem = 4\n",
    "    spambase_problem = 5\n",
    "#getDataPaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify ProblemDataProvider component for sourcing problem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemDataProvider(object):\n",
    "    def __init__(self,problem_type):\n",
    "        self.__problem_type = problem_type\n",
    "        self.__problem_path_map = ProblemDataProvider.getProblemDataPaths(problem_type)\n",
    "        self.__problem_data_map = self.readData()\n",
    "        self.__le = preprocessing.LabelEncoder()\n",
    "        self.__pre_processed_data_map = self.preProcessData()\n",
    "        self.__data_matrix_map = self.dataAsMatrix()\n",
    "        \n",
    "    def __str__(self):\n",
    "        msg = f'problem_type: {self.__problem_type}'\n",
    "        msg += f'{NEW_LINE}problem_path_map: {self.__problem_path_map}{NEW_LINE}'\n",
    "        for k, v in self.__problem_data_map.items():\n",
    "            msg += f'{self.__problem_path_map[k]} data has the shape: {self.__problem_data_map[k].shape}{NEW_LINE}'\n",
    "        msg += f'{NEW_LINE}'\n",
    "        return msg\n",
    "    \n",
    "    def readData(self):\n",
    "        data_map = {}\n",
    "        for k, v in self.__problem_path_map.items():\n",
    "            data_map[k] = pd.read_csv(v)\n",
    "        return data_map\n",
    "    \n",
    "    def preProcessData(self):\n",
    "        data_map = {}\n",
    "        for k, v in self.__problem_data_map.items():\n",
    "            data_map[k] = self.applyPreProcessorPerDataset(k, v)\n",
    "        return data_map\n",
    "    \n",
    "    def applyPreProcessorPerDataset(self, key, old_data_df):\n",
    "        if self.__problem_type == ProblemType.spambase_problem:\n",
    "            new_data_df = old_data_df.copy()\n",
    "            new_data_df = new_data_df.drop('Id', 1)\n",
    "            new_data_df.capital_run_length_longest = new_data_df.capital_run_length_longest.astype(float)\n",
    "            new_data_df.capital_run_length_total = new_data_df.capital_run_length_total.astype(float)\n",
    "#             if key is 'train':                \n",
    "#                 new_data_df.ham = new_data_df.ham.astype(int)\n",
    "        return new_data_df\n",
    "    \n",
    "    def dataAsMatrix(self):\n",
    "        data_map = {}\n",
    "        for k, v in self.__pre_processed_data_map.items():\n",
    "            data_map[k] = v.values\n",
    "        return data_map\n",
    "    \n",
    "    @property\n",
    "    def problem_type(self):\n",
    "        return self.__problem_type\n",
    "    \n",
    "    @property\n",
    "    def problem_path_map(self):\n",
    "        return self.__problem_path_map\n",
    "    \n",
    "    @property\n",
    "    def problem_data_map(self):\n",
    "        return self.__problem_data_map\n",
    "    \n",
    "    @property\n",
    "    def pre_processed_data_map(self):\n",
    "        return self.__pre_processed_data_map\n",
    "    \n",
    "    @property\n",
    "    def data_matrix_map(self):\n",
    "        return self.__data_matrix_map\n",
    "    \n",
    "    @staticmethod\n",
    "    def isTestDataPath(path):\n",
    "        head, tail = os.path.split(path)\n",
    "        if tail.split('_')[1].lower() .startswith('test'):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def getProblemDataPaths(problem_type):\n",
    "        found_paths = []\n",
    "        paths_map = {}\n",
    "        key = problem_type.name.split('_')[0].lower()\n",
    "        print('key: {}'.format(key))\n",
    "        paths = getDataPaths()\n",
    "        print(f'There are {len(paths)} Problem data files found, they include:')\n",
    "        for x in paths:\n",
    "            head, tail = os.path.split(x)\n",
    "            print(f'{x}')\n",
    "            if tail.startswith(key):\n",
    "                found_paths.append(x)\n",
    "        #print(f'found_paths: {found_paths}')\n",
    "        if len(found_paths) > 1:\n",
    "            for path in found_paths:\n",
    "                if ProblemDataProvider.isTestDataPath(path):\n",
    "                    paths_map['test'] = path\n",
    "                else:\n",
    "                    paths_map['train'] = path\n",
    "        else:\n",
    "            paths_map['all'] = found_paths[0]\n",
    "        print(f'{problem_type.name} paths_map is: {paths_map}')\n",
    "        return paths_map\n",
    "\n",
    "         \n",
    "    \n",
    "        \n",
    "# spambase_data = pd.read_csv(SPAMBASE_TEST)\n",
    "# spambase_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ProblemDataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: spambase\n",
      "There are 7 Problem data files found, they include:\n",
      ".\\Data\\breast-cancer-wisconsin.csv\n",
      ".\\Data\\horse-colic.csv\n",
      ".\\Data\\ionosphere.csv\n",
      ".\\Data\\pima-indians-diabetes.csv\n",
      ".\\Data\\sonar.csv\n",
      ".\\Data\\spambase_test_data.csv\n",
      ".\\Data\\spambase_train_data.csv\n",
      "spambase_problem paths_map is: {'test': '.\\\\Data\\\\spambase_test_data.csv', 'train': '.\\\\Data\\\\spambase_train_data.csv'}\n",
      "\n",
      "data_provider: problem_type: ProblemType.spambase_problem\n",
      "problem_path_map: {'test': '.\\\\Data\\\\spambase_test_data.csv', 'train': '.\\\\Data\\\\spambase_train_data.csv'}\n",
      ".\\Data\\spambase_test_data.csv data has the shape: (921, 58)\n",
      ".\\Data\\spambase_train_data.csv data has the shape: (3680, 59)\n",
      "\n",
      "\n",
      "Problem map keys: dict_keys(['test', 'train'])\n",
      "train data:    word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0             0.0              14.28            0.0           0.0   \n",
      "1             0.0               0.00            1.0           0.0   \n",
      "2             0.0               0.00            0.0           0.0   \n",
      "3             0.0               0.00            0.0           0.0   \n",
      "4             0.0               0.00            0.0           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.00             0.0               0.0                0.00   \n",
      "1           0.50             0.0               0.0                0.00   \n",
      "2           0.00             0.0               0.0                1.29   \n",
      "3           0.00             0.0               0.0                0.00   \n",
      "4           1.17             0.0               0.0                0.00   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0              0.0            0.00  ...          0.0        0.000   \n",
      "1              0.0            0.50  ...          0.0        0.357   \n",
      "2              0.0            0.43  ...          0.0        0.124   \n",
      "3              0.0            0.00  ...          0.0        0.000   \n",
      "4              0.0            1.17  ...          0.0        0.000   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0          0.0        0.000        0.000          0.0   \n",
      "1          0.0        0.892        0.000          0.0   \n",
      "2          0.0        0.310        0.062          0.0   \n",
      "3          0.0        0.444        0.000          0.0   \n",
      "4          0.0        0.000        0.000          0.0   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       1.800                         5.0   \n",
      "1                       2.000                        19.0   \n",
      "2                       1.477                         8.0   \n",
      "3                       2.800                         7.0   \n",
      "4                       1.551                        10.0   \n",
      "\n",
      "   capital_run_length_total    ham  \n",
      "0                       9.0   True  \n",
      "1                     172.0  False  \n",
      "2                      65.0  False  \n",
      "3                      28.0   True  \n",
      "4                      45.0   True  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "\n",
      "\n",
      "\n",
      "train data types: word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest    float64\n",
      "capital_run_length_total      float64\n",
      "ham                              bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "problem_type = ProblemType.spambase_problem\n",
    "data_provider = ProblemDataProvider(problem_type)\n",
    "print(f'\\ndata_provider: {data_provider}')\n",
    "problem_raw_data_map = data_provider.problem_data_map\n",
    "problem_clean_data_map = data_provider.pre_processed_data_map\n",
    "problem_map_keys = problem_raw_data_map.keys()\n",
    "print(f'Problem map keys: {problem_map_keys}')\n",
    "train_data = problem_clean_data_map['train'].head(5)\n",
    "test_data = problem_clean_data_map['test'].head(5)\n",
    "print(f'train data: {train_data}')\n",
    "print('\\n\\n')\n",
    "print(f'train data types: {train_data.dtypes}')\n",
    "#print(f'test data: {problem_clean_data_map['test'].head(5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Problem Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def breastCancerEvalFunc(data, individual):\n",
    "    pass\n",
    "\n",
    "def horseEvalFunc(data, individual):\n",
    "    pass\n",
    "\n",
    "def ionosphereEvalFunc(data, individual):\n",
    "    pass\n",
    "\n",
    "def pimaEvalFunc(data, individual):\n",
    "    pass\n",
    "\n",
    "def sonarEvalFunc(data, individual):\n",
    "    pass\n",
    "\n",
    "def spambaseEvalFunc(spam, individual):\n",
    "    # Transform the tree expression in a callable function\n",
    "    func = toolbox.lambdify(expr=individual)\n",
    "    # Randomly sample 400 mails in the spam database (defined before)\n",
    "    spam_samp = random.sample(spam, 400)\n",
    "    # Evaluate the sum of correctly identified mail as spam\n",
    "    result = sum(bool(func(*mail[:57])) is bool(mail[57]) for mail in spam_samp)\n",
    "    return result,\n",
    "\n",
    "class ProblemEvaluationFuncProvider(object):\n",
    "    def __init__(self, problem_type):\n",
    "        self.__problem_type = problem_type\n",
    "        self.__eval_func_map = eval_func_map = {\n",
    "            ProblemType.breast_cancer_problem: breastCancerEvalFunc,\n",
    "            ProblemType.horse_problem: horseEvalFunc,\n",
    "            ProblemType.ionospere_problem: ionosphereEvalFunc,\n",
    "            ProblemType.pima_problem: pimaEvalFunc,\n",
    "            ProblemType.sonar_problem: sonarEvalFunc,\n",
    "            ProblemType.spambase_problem: spambaseEvalFunc\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def eval_func(self):        \n",
    "        return self.__eval_func_map[self.__problem_type]\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: spambase\n",
      "There are 7 Problem data files found, they include:\n",
      ".\\Data\\breast-cancer-wisconsin.csv\n",
      ".\\Data\\horse-colic.csv\n",
      ".\\Data\\ionosphere.csv\n",
      ".\\Data\\pima-indians-diabetes.csv\n",
      ".\\Data\\sonar.csv\n",
      ".\\Data\\spambase_test_data.csv\n",
      ".\\Data\\spambase_train_data.csv\n",
      "spambase_problem paths_map is: {'test': '.\\\\Data\\\\spambase_test_data.csv', 'train': '.\\\\Data\\\\spambase_train_data.csv'}\n",
      "Training data size is: (3680, 58)\n",
      "Testing data size is: (921, 57)\n",
      "Sample (2) rows of train_data:\n",
      "[[0.0 14.28 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 1.8 5.0 9.0 True]\n",
      " [0.0 0.0 1.0 0.0 0.5 0.0 0.0 0.0 0.0 0.5 0.0 0.0 0.0 0.0 0.0 0.5 0.0 0.0\n",
      "  2.5 0.0 1.5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.5 0.0 0.0 0.0 0.0 0.35700000000000004\n",
      "  0.0 0.892 0.0 0.0 2.0 19.0 172.0 False]]\n",
      "Evaluation function for spambase_problem is <function spambaseEvalFunc at 0x00000163BE0DA378>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-403a3cf8db27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtrainGPModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mrunDemoForSpamProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-403a3cf8db27>\u001b[0m in \u001b[0;36mrunDemoForSpamProblem\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Evaluation function for {problem_type.name} is {eval_func}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#result = eval_func(train_data.tolist(), None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrainGPModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mrunDemoForSpamProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-403a3cf8db27>\u001b[0m in \u001b[0;36mtrainGPModel\u001b[1;34m(eval_func, train_data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrainGPModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrunDemoForSpamProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\development\\python\\AI\\GeneticAlgorithms\\GeneticProgramming\\BinaryClassification\\DeapWrapperComponent.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(eval_func, data)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mprimitive_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstructPrimitiveSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mtoolbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstructToolBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprimitive_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mpop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\development\\python\\AI\\GeneticAlgorithms\\GeneticProgramming\\BinaryClassification\\DeapWrapperComponent.py\u001b[0m in \u001b[0;36mconstructPrimitiveSet\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconstructPrimitiveSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# defined a new primitive set for strongly typed GP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mpset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrimitiveSetTyped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAIN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# boolean operators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\DeeplearningEnv\\lib\\site-packages\\deap\\gp.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, in_types, ret_type, prefix)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mterm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTerminal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterms_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\DeeplearningEnv\\lib\\site-packages\\deap\\gp.py\u001b[0m in \u001b[0;36m_add\u001b[1;34m(self, prim)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m                 \u001b[0mdict_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "def trainGPModel(eval_func, train_data):\n",
    "    pop, stats, hof = de.run(eval_func, train_data)\n",
    "\n",
    "\n",
    "def runDemoForSpamProblem():\n",
    "    problem_type = ProblemType.spambase_problem\n",
    "    data_provider = ProblemDataProvider(problem_type)\n",
    "    data_map = data_provider.data_matrix_map\n",
    "    train_data = data_map['train']\n",
    "    test_data = data_map['test']\n",
    "    print(f'Training data size is: {train_data.shape}')\n",
    "    print(f'Testing data size is: {test_data.shape}')\n",
    "    print(f\"Sample (2) rows of train_data:{NEW_LINE}{train_data[:2]}\")\n",
    "    eval_func_provider = ProblemEvaluationFuncProvider(problem_type)\n",
    "    eval_func = eval_func_provider.eval_func\n",
    "    print(f\"Evaluation function for {problem_type.name} is {eval_func}\")\n",
    "    #result = eval_func(train_data.tolist(), None)\n",
    "    trainGPModel(eval_func, train_data)\n",
    "    \n",
    "runDemoForSpamProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
